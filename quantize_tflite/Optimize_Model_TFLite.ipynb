{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Y8E0lw5eYWm"
   },
   "source": [
    "# Post Training Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BTC1rDAuei_1"
   },
   "source": [
    "## Overview\n",
    "\n",
    "[TensorFlow Lite](https://www.tensorflow.org/lite/) now supports\n",
    "converting weights to 8 bit precision as part of model conversion from\n",
    "tensorflow graphdefs to TFLite's flat buffer format. Weight quantization\n",
    "achieves a 4x reduction in the model size. In addition, TFLite supports on the\n",
    "fly quantization and dequantization of activations to allow for:\n",
    "\n",
    "1.  Using quantized kernels for faster implementation when available.\n",
    "\n",
    "2.  Mixing of floating-point kernels with quantized kernels for different parts\n",
    "    of the graph.\n",
    "\n",
    "Note that the activations are always stored in floating point. For ops that\n",
    "support quantized kernels, the activations are quantized to 8 bits of precision\n",
    "dynamically prior to processing and are de-quantized to float precision after\n",
    "processing. Depending on the model being converted, this can give a speedup over\n",
    "pure floating point computation.\n",
    "\n",
    "In contrast to\n",
    "[quantization aware training](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/quantize)\n",
    ", the weights are quantized post training and the activations are quantized dynamically \n",
    "at inference in this method.\n",
    "Therefore, the model weights are not retrained to compensate for quantization\n",
    "induced errors. It is important to check the accuracy of the quantized model to\n",
    "ensure that the degradation is acceptable.\n",
    "\n",
    "In this tutorial, we train an MNIST model from scratch, check its accuracy in\n",
    "tensorflow and then convert the saved model into a Tensorflow Lite flatbuffer\n",
    "with weight quantization. We finally check the\n",
    "accuracy of the converted model and compare it to the original saved model. We\n",
    "run the training script mnist.py from\n",
    "[Tensorflow official mnist tutorial](https://github.com/tensorflow/models/tree/master/official/mnist).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2XsEP17Zelz9"
   },
   "source": [
    "## Building an MNIST model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dDqqUIZjZjac"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gyqAw1M9lyab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mCannot uninstall requirement tensorflow, not installed\u001b[0m\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tf-nightly\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/a5/162858bb8ee3bbd7320a13242f6d3be0ecd70154a52c3e1c1078615bd045/tf_nightly-1.12.0.dev20180922-cp36-cp36m-manylinux1_x86_64.whl (63.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 63.7MB 21kB/s \n",
      "\u001b[?25hRequirement already up-to-date: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tf-nightly)\n",
      "Collecting tb-nightly<1.12.0a0,>=1.11.0a0 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/84/93/fe1018e4449c7f809dd08a730821cd4b79e2ce6188f22ee84f42e20eead3/tb_nightly-1.11.0a20180922-py3-none-any.whl (3.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.0MB 436kB/s \n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.3 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/bd/796f986980da4d6adc77ffd8b2b11074e7b17a7b74b03789aefac5709c4b/Keras_Preprocessing-1.0.3-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.5 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/9c/6e9393ead970fd97be0cfde912697dafec5800d9191f5ba25352fa537d72/Keras_Applications-1.0.5-py2.py3-none-any.whl (44kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 11.5MB/s \n",
      "\u001b[?25hRequirement already up-to-date: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tf-nightly)\n",
      "Requirement already up-to-date: protobuf>=3.6.0 in /opt/conda/lib/python3.6/site-packages (from tf-nightly)\n",
      "Requirement already up-to-date: absl-py>=0.1.6 in /opt/conda/lib/python3.6/site-packages (from tf-nightly)\n",
      "Requirement already up-to-date: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from tf-nightly)\n",
      "Collecting setuptools<=39.1.0 (from tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\n",
      "\u001b[K    100% |████████████████████████████████| 573kB 2.4MB/s \n",
      "\u001b[?25hRequirement already up-to-date: termcolor>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from tf-nightly)\n",
      "Requirement already up-to-date: astor>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tf-nightly)\n",
      "Requirement already up-to-date: grpcio>=1.8.6 in /opt/conda/lib/python3.6/site-packages (from tf-nightly)\n",
      "Requirement already up-to-date: gast>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from tf-nightly)\n",
      "Requirement already up-to-date: werkzeug>=0.11.10 in /opt/conda/lib/python3.6/site-packages (from tb-nightly<1.12.0a0,>=1.11.0a0->tf-nightly)\n",
      "Collecting markdown>=2.6.8 (from tb-nightly<1.12.0a0,>=1.11.0a0->tf-nightly)\n",
      "  Downloading https://files.pythonhosted.org/packages/7a/fd/e22357c299e93c0bc11ec8ba54e79f98dd568e09adfe9b39d6852c744938/Markdown-3.0-py2.py3-none-any.whl (89kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 11.6MB/s \n",
      "\u001b[?25hRequirement already up-to-date: keras>=2.1.6 in /opt/conda/lib/python3.6/site-packages (from keras-preprocessing>=1.0.3->tf-nightly)\n",
      "Requirement already up-to-date: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from keras-preprocessing>=1.0.3->tf-nightly)\n",
      "Requirement already up-to-date: h5py in /opt/conda/lib/python3.6/site-packages (from keras-applications>=1.0.5->tf-nightly)\n",
      "Requirement already up-to-date: pyyaml in /opt/conda/lib/python3.6/site-packages (from keras>=2.1.6->keras-preprocessing>=1.0.3->tf-nightly)\n",
      "Installing collected packages: markdown, tb-nightly, keras-preprocessing, keras-applications, setuptools, tf-nightly\n",
      "  Found existing installation: Markdown 2.6.11\n",
      "    Uninstalling Markdown-2.6.11:\n",
      "      Successfully uninstalled Markdown-2.6.11\n",
      "  Found existing installation: Keras-Preprocessing 1.0.2\n",
      "    Uninstalling Keras-Preprocessing-1.0.2:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.0.2\n",
      "  Found existing installation: Keras-Applications 1.0.4\n",
      "    Uninstalling Keras-Applications-1.0.4:\n",
      "      Successfully uninstalled Keras-Applications-1.0.4\n",
      "  Found existing installation: setuptools 40.4.1\n",
      "    Uninstalling setuptools-40.4.1:\n",
      "      Successfully uninstalled setuptools-40.4.1\n",
      "Successfully installed keras-applications-1.0.5 keras-preprocessing-1.0.3 markdown-3.0 setuptools-39.1.0 tb-nightly-1.11.0a20180922 tf-nightly-1.12.0.dev20180922\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip uninstall -y tensorflow\n",
    "! pip install -U tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WsN6s5L1ieNl"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00U0taBoe-w7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 2915, done.\u001b[K\n",
      "remote: Counting objects: 100% (2915/2915), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2530/2530), done.\u001b[K\n",
      "remote: Total 2915 (delta 500), reused 1743 (delta 313), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (2915/2915), 376.37 MiB | 54.09 MiB/s, done.\n",
      "Resolving deltas: 100% (500/500), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "! git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4XZPtSh-fUOc"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "if sys.version_info.major >= 3:\n",
    "    import pathlib\n",
    "else:\n",
    "    import pathlib2 as pathlib\n",
    "\n",
    "# Add `models` to the python path.\n",
    "models_path = os.path.join(os.getcwd(), \"models\")\n",
    "sys.path.append(models_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eQ6Q0qqKZogR"
   },
   "source": [
    "### Train and export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMsw_6HujaqM"
   },
   "outputs": [],
   "source": [
    "saved_models_root = \"/tmp/mnist_saved_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWSAjQWagIHl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-09-22 17:22:42.896671: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "I0922 17:22:46.298367 140509021062912 tf_logging.py:115] Initializing RunConfig with distribution strategies.\n",
      "I0922 17:22:46.298596 140509021062912 tf_logging.py:115] Not using Distribute Coordinator.\n",
      "I0922 17:22:46.298949 140509021062912 tf_logging.py:115] Using config: {'_model_dir': '/tmp/mnist_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.one_device_strategy.OneDeviceStrategy object at 0x7fca3a0eae10>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fca3a0eae80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n",
      "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz to /tmp/tmp7x5nur41.gz\n",
      "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/train-labels-idx1-ubyte.gz to /tmp/tmpiobbsjf7.gz\n",
      "I0922 17:22:47.123925 140509021062912 tf_logging.py:115] Calling model_fn.\n",
      "I0922 17:22:47.594112 140509021062912 tf_logging.py:115] Done calling model_fn.\n",
      "I0922 17:22:47.633873 140509021062912 tf_logging.py:115] Create CheckpointSaverHook.\n",
      "I0922 17:22:47.805945 140509021062912 tf_logging.py:115] Graph was finalized.\n",
      "I0922 17:22:48.063200 140509021062912 tf_logging.py:115] Running local_init_op.\n",
      "I0922 17:22:48.070763 140509021062912 tf_logging.py:115] Done running local_init_op.\n",
      "I0922 17:22:48.464334 140509021062912 tf_logging.py:115] Saving checkpoints for 0 into /tmp/mnist_model/model.ckpt.\n",
      "I0922 17:22:48.610753 140509021062912 tf_logging.py:115] Initialize system\n",
      "I0922 17:22:54.237657 140509021062912 tf_logging.py:115] cross_entropy = 2.3033733, learning_rate = 1e-04, train_accuracy = 0.14\n",
      "I0922 17:22:54.238066 140509021062912 tf_logging.py:115] loss = 2.3033733, step = 0\n",
      "I0922 17:23:04.817899 140509021062912 tf_logging.py:115] global_step/sec: 9.45127\n",
      "I0922 17:23:04.818545 140509021062912 tf_logging.py:115] cross_entropy = 0.39357528, learning_rate = 1e-04, train_accuracy = 0.53 (10.581 sec)\n",
      "I0922 17:23:04.818714 140509021062912 tf_logging.py:115] loss = 0.39357528, step = 100 (10.581 sec)\n",
      "I0922 17:23:14.154668 140509021062912 tf_logging.py:115] global_step/sec: 10.7103\n",
      "I0922 17:23:14.155296 140509021062912 tf_logging.py:115] cross_entropy = 0.40696067, learning_rate = 1e-04, train_accuracy = 0.65 (9.337 sec)\n",
      "I0922 17:23:14.155556 140509021062912 tf_logging.py:115] loss = 0.40696067, step = 200 (9.337 sec)\n",
      "I0922 17:23:22.893039 140509021062912 tf_logging.py:115] global_step/sec: 11.4438\n",
      "I0922 17:23:22.893700 140509021062912 tf_logging.py:115] cross_entropy = 0.16676623, learning_rate = 1e-04, train_accuracy = 0.725 (8.738 sec)\n",
      "I0922 17:23:22.893941 140509021062912 tf_logging.py:115] loss = 0.16676623, step = 300 (8.738 sec)\n",
      "I0922 17:23:31.112667 140509021062912 tf_logging.py:115] global_step/sec: 12.166\n",
      "I0922 17:23:31.113474 140509021062912 tf_logging.py:115] cross_entropy = 0.20728068, learning_rate = 1e-04, train_accuracy = 0.768 (8.220 sec)\n",
      "I0922 17:23:31.113795 140509021062912 tf_logging.py:115] loss = 0.20728068, step = 400 (8.220 sec)\n",
      "I0922 17:23:39.396701 140509021062912 tf_logging.py:115] global_step/sec: 12.0714\n",
      "I0922 17:23:39.397411 140509021062912 tf_logging.py:115] cross_entropy = 0.15384305, learning_rate = 1e-04, train_accuracy = 0.8 (8.284 sec)\n",
      "I0922 17:23:39.397622 140509021062912 tf_logging.py:115] loss = 0.15384305, step = 500 (8.284 sec)\n",
      "I0922 17:23:47.455689 140509021062912 tf_logging.py:115] Saving checkpoints for 600 into /tmp/mnist_model/model.ckpt.\n",
      "I0922 17:23:47.540983 140509021062912 tf_logging.py:115] Finalize system.\n",
      "I0922 17:23:47.580952 140509021062912 tf_logging.py:115] Loss for final step: 0.06267746.\n",
      "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz to /tmp/tmpjb1k434p.gz\n",
      "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmps96vmaru.gz\n",
      "I0922 17:23:47.821016 140509021062912 tf_logging.py:115] Calling model_fn.\n",
      "I0922 17:23:47.993024 140509021062912 tf_logging.py:115] Done calling model_fn.\n",
      "I0922 17:23:48.015085 140509021062912 tf_logging.py:115] Starting evaluation at 2018-09-22-17:23:48\n",
      "I0922 17:23:48.098277 140509021062912 tf_logging.py:115] Graph was finalized.\n",
      "I0922 17:23:48.099883 140509021062912 tf_logging.py:115] Restoring parameters from /tmp/mnist_model/model.ckpt-600\n",
      "I0922 17:23:48.129198 140509021062912 tf_logging.py:115] Running local_init_op.\n",
      "I0922 17:23:48.136913 140509021062912 tf_logging.py:115] Done running local_init_op.\n",
      "I0922 17:23:51.461297 140509021062912 tf_logging.py:115] Finished evaluation at 2018-09-22-17:23:51\n",
      "I0922 17:23:51.461605 140509021062912 tf_logging.py:115] Saving dict for global step 600: accuracy = 0.9689, global_step = 600, loss = 0.09934009\n",
      "I0922 17:23:51.511727 140509021062912 tf_logging.py:115] Saving 'checkpoint_path' summary for global step 600: /tmp/mnist_model/model.ckpt-600\n",
      "\n",
      "Evaluation results:\n",
      "\t{'accuracy': 0.9689, 'loss': 0.09934009, 'global_step': 600}\n",
      "\n",
      "I0922 17:23:51.519250 140509021062912 tf_logging.py:115] Calling model_fn.\n",
      "I0922 17:23:51.648442 140509021062912 tf_logging.py:115] Done calling model_fn.\n",
      "I0922 17:23:51.648833 140509021062912 tf_logging.py:115] Signatures INCLUDED in export for Classify: None\n",
      "I0922 17:23:51.648924 140509021062912 tf_logging.py:115] Signatures INCLUDED in export for Regress: None\n",
      "I0922 17:23:51.648997 140509021062912 tf_logging.py:115] Signatures INCLUDED in export for Predict: ['classify', 'serving_default']\n",
      "I0922 17:23:51.649060 140509021062912 tf_logging.py:115] Signatures INCLUDED in export for Train: None\n",
      "I0922 17:23:51.649118 140509021062912 tf_logging.py:115] Signatures INCLUDED in export for Eval: None\n",
      "I0922 17:23:51.674698 140509021062912 tf_logging.py:115] Restoring parameters from /tmp/mnist_model/model.ckpt-600\n",
      "W0922 17:23:51.689255 140509021062912 tf_logging.py:125] From /opt/conda/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1020: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n",
      "I0922 17:23:51.689451 140509021062912 tf_logging.py:115] Assets added to graph.\n",
      "I0922 17:23:51.689560 140509021062912 tf_logging.py:115] No assets to write.\n",
      "I0922 17:23:51.726562 140509021062912 tf_logging.py:115] SavedModel written to: /tmp/mnist_saved_model/temp-b'1537637031'/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "# The above path addition is not visible to subprocesses, add the path for the subprocess as well.\n",
    "# Note: channels_last is required here or the conversion may fail. \n",
    "!PYTHONPATH={models_path} python models/official/mnist/mnist.py --train_epochs=1 --export_dir {saved_models_root} --data_format=channels_last"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5NMaNZQCkW9X"
   },
   "source": [
    "For the example, we only trained the model for a single epoch, so it only trains to ~96% accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xl8_fzVAZwOh"
   },
   "source": [
    "### Convert to a TFLite model\n",
    "\n",
    "The `savedmodel` directory is named with a timestamp. Select the most recent one: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xp5oClaZkbtn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/mnist_saved_model/1537637031'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model_dir = str(sorted(pathlib.Path(saved_models_root).glob(\"*\"))[-1])\n",
    "saved_model_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AT8BgkKmljOy"
   },
   "source": [
    "Using the python `TocoConverter`, the saved model can be converted into a TFLite model.\n",
    "\n",
    "First load the model using the `TocoConverter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_i8B2nDZmAgQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_saved_model/1537637031/variables/variables\n",
      "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'classify', 'serving_default'}\n",
      "INFO:tensorflow:input tensors info: \n",
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: image\n",
      "INFO:tensorflow: tensor name: Placeholder:0, shape: (-1, 28, 28), type: DT_FLOAT\n",
      "INFO:tensorflow:output tensors info: \n",
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: classes\n",
      "INFO:tensorflow: tensor name: ArgMax:0, shape: (-1), type: DT_INT64\n",
      "INFO:tensorflow:Tensor's key in saved_model's tensor_map: probabilities\n",
      "INFO:tensorflow: tensor name: Softmax:0, shape: (-1, 10), type: DT_FLOAT\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_saved_model/1537637031/variables/variables\n",
      "INFO:tensorflow:Froze 8 variables.\n",
      "INFO:tensorflow:Converted 8 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "converter = tf.contrib.lite.TocoConverter.from_saved_model(saved_model_dir)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F2o2ZfF0aiCx"
   },
   "source": [
    "Write it out to a tflite file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vptWZq2xnclo"
   },
   "outputs": [],
   "source": [
    "tflite_models_dir = pathlib.Path(\"/tmp/mnist_tflite_models/\")\n",
    "tflite_models_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ie9pQaQrn5ue"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13101280"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tflite_model_file = tflite_models_dir/\"mnist_model.tflite\"\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7BONhYtYocQY"
   },
   "source": [
    "To quantize the model on export, set the `post_training_quantize` flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8PUvLWDlmmz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3283208"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note: If you don't have a recent tf-nightly installed, the\n",
    "# \"post_training_quantize\" line will have no effect.\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "converter.post_training_quantize = True\n",
    "tflite_quant_model = converter.convert()\n",
    "tflite_model_quant_file = tflite_models_dir/\"mnist_model_quant.tflite\"\n",
    "tflite_model_quant_file.write_bytes(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PhMmUTl4sbkz"
   },
   "source": [
    "Note how the resulting file, with `post_training_quantize` set, is approximately `1/4` the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JExfcfLDscu4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16M\n",
      "-rw-r--r-- 1 root root  13M Sep 22 17:24 mnist_model.tflite\n",
      "-rw-r--r-- 1 root root 3.2M Sep 22 17:24 mnist_model_quant.tflite\n"
     ]
    }
   ],
   "source": [
    "!ls -lh {tflite_models_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L8lQHMp_asCq"
   },
   "source": [
    "## Run the TFLite models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5l6-ciItvX6"
   },
   "source": [
    "We can run the TensorFlow Lite model using the python TensorFlow Lite\n",
    "Interpreter. \n",
    "\n",
    "### load the test data\n",
    "\n",
    "First let's load the mnist test data to feed to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eTIuU07NuKFL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()\n",
    "images, labels = tf.to_float(mnist_test[0])/255.0, mnist_test[1]\n",
    "\n",
    "# Note: If you change the batch size, then use \n",
    "# `tf.contrib.lite.Interpreter.resize_tensor_input` to also change it for\n",
    "# the interpreter.\n",
    "mnist_ds = tf.data.Dataset.from_tensor_slices((images, labels)).batch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ap_jE7QRvhPf"
   },
   "source": [
    "### Load the model into an interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jn16Rc23zTss"
   },
   "outputs": [],
   "source": [
    "interpreter = tf.contrib.lite.Interpreter(model_path=str(tflite_model_file))\n",
    "interpreter.allocate_tensors()\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J8Pztk1mvNVL"
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "interpreter_quant = tf.contrib.lite.Interpreter(model_path=str(tflite_model_quant_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Afl6yGvWyqAr"
   },
   "outputs": [],
   "source": [
    "interpreter_quant.allocate_tensors()\n",
    "input_index = interpreter_quant.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter_quant.get_output_details()[0][\"index\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2opUt_JTdyEu"
   },
   "source": [
    "### Test the model on one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AKslvo2kwWac"
   },
   "outputs": [],
   "source": [
    "for img, label in mnist_ds.take(1):\n",
    "  break\n",
    "\n",
    "interpreter.set_tensor(input_index, img)\n",
    "interpreter.invoke()\n",
    "predictions = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZClM2vo3_bm"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.imshow(img[0])\n",
    "template = \"True:{true}, predicted:{predict}\"\n",
    "_ = plt.title(template.format(true= str(label[0].numpy()),\n",
    "                              predict=str(predictions[0,0])))\n",
    "plt.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LwN7uIdCd8Gw"
   },
   "source": [
    "### Evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05aeAuWjvjPx"
   },
   "outputs": [],
   "source": [
    "def eval_model(interpreter, mnist_ds):\n",
    "  total_seen = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for img, label in mnist_ds:\n",
    "    total_seen += 1\n",
    "    interpreter.set_tensor(input_index, img)\n",
    "    interpreter.invoke()\n",
    "    predictions = interpreter.get_tensor(output_index)\n",
    "    if predictions == label.numpy():\n",
    "      num_correct += 1\n",
    "\n",
    "    if total_seen % 500 == 0:\n",
    "        print(\"Accuracy after %i images: %f\" %\n",
    "              (total_seen, float(num_correct) / float(total_seen)))\n",
    "\n",
    "  return float(num_correct) / float(total_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DqXBnDfJ7qxL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 500 images: 0.978000\n",
      "Accuracy after 1000 images: 0.968000\n",
      "Accuracy after 1500 images: 0.962000\n",
      "Accuracy after 2000 images: 0.958500\n",
      "Accuracy after 2500 images: 0.956000\n",
      "Accuracy after 3000 images: 0.960000\n",
      "Accuracy after 3500 images: 0.960857\n",
      "Accuracy after 4000 images: 0.957500\n",
      "Accuracy after 4500 images: 0.956889\n",
      "Accuracy after 5000 images: 0.956000\n",
      "Accuracy after 5500 images: 0.959455\n",
      "Accuracy after 6000 images: 0.960000\n",
      "Accuracy after 6500 images: 0.961538\n",
      "Accuracy after 7000 images: 0.962429\n",
      "Accuracy after 7500 images: 0.964267\n",
      "Accuracy after 8000 images: 0.965750\n",
      "Accuracy after 8500 images: 0.966824\n",
      "Accuracy after 9000 images: 0.968556\n",
      "Accuracy after 9500 images: 0.969579\n",
      "Accuracy after 10000 images: 0.968900\n",
      "0.9689\n"
     ]
    }
   ],
   "source": [
    "print(eval_model(interpreter, mnist_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Km3cY9ry8ZlG"
   },
   "source": [
    "We can repeat the evaluation on the weight quantized model to obtain:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-9cnwiPp6EGm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy after 500 images: 0.978000\n",
      "Accuracy after 1000 images: 0.968000\n",
      "Accuracy after 1500 images: 0.962000\n",
      "Accuracy after 2000 images: 0.958500\n",
      "Accuracy after 2500 images: 0.956000\n",
      "Accuracy after 3000 images: 0.960000\n",
      "Accuracy after 3500 images: 0.960857\n",
      "Accuracy after 4000 images: 0.957500\n",
      "Accuracy after 4500 images: 0.956889\n",
      "Accuracy after 5000 images: 0.956000\n",
      "Accuracy after 5500 images: 0.959455\n",
      "Accuracy after 6000 images: 0.960000\n",
      "Accuracy after 6500 images: 0.961692\n",
      "Accuracy after 7000 images: 0.962571\n",
      "Accuracy after 7500 images: 0.964400\n",
      "Accuracy after 8000 images: 0.965875\n",
      "Accuracy after 8500 images: 0.966941\n",
      "Accuracy after 9000 images: 0.968667\n",
      "Accuracy after 9500 images: 0.969684\n",
      "Accuracy after 10000 images: 0.969000\n",
      "0.969\n"
     ]
    }
   ],
   "source": [
    "print(eval_model(interpreter_quant, mnist_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7lfxkor8pgv"
   },
   "source": [
    "\n",
    "In this example, we have compressed model with no difference in the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M0o1FtmWeKZm"
   },
   "source": [
    "\n",
    "\n",
    "## Optimizing an existing model\n",
    "\n",
    "We now consider another example. Resnets with pre-activation layers (Resnet-v2) are widely used for vision applications.\n",
    "  Pre-trained frozen graph for resnet-v2-101 is available at the\n",
    "  [Tensorflow Lite model repository](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/models.md).\n",
    "\n",
    "We can convert the frozen graph to a TFLite flatbuffer with quantization by:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5p5VcNPjILQ"
   },
   "outputs": [],
   "source": [
    "archive_path = tf.keras.utils.get_file(\"resnet_v2_101.tgz\", \"https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/resnet_v2_101.tgz\", extract=True)\n",
    "archive_path = pathlib.Path(archive_path)\n",
    "archive_dir = str(archive_path.parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-sxnXQuC4ThD"
   },
   "source": [
    "The `info.txt` file lists the input and output names. You can also find them using TensorBoard to visually inspect the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_Q_OMEJ4LIc"
   },
   "outputs": [],
   "source": [
    "! cat {archive_dir}/resnet_v2_101_299_info.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ujCAFhqm-C6H"
   },
   "outputs": [],
   "source": [
    "graph_def_file = pathlib.Path(archive_path).parent/\"resnet_v2_101_299_frozen.pb\"\n",
    "input_arrays = [\"input\"] \n",
    "output_arrays = [\"output\"]\n",
    "converter = tf.contrib.lite.TocoConverter.from_frozen_graph(\n",
    "  str(graph_def_file), input_arrays, output_arrays, input_shapes={\"input\":[1,299,299,3]})\n",
    "converter.post_training_quantize = True\n",
    "resnet_tflite_file = graph_def_file.parent/\"resnet_v2_101_quantized.tflite\"\n",
    "resnet_tflite_file.write_bytes(converter.convert())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vhOjeg1x9Knp"
   },
   "outputs": [],
   "source": [
    "\n",
    "!ls -lh {archive_dir}/*.tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qqHLaqFMCjRZ"
   },
   "source": [
    "\n",
    "The model size reduces from 171 MB to 43 MB.\n",
    "The accuracy of this model on imagenet can be evaluated using the scripts provided for [TFLite accuracy measurement](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/tools/accuracy/ilsvrc).\n",
    "\n",
    "The optimized model top-1 accuracy is 76.8, the same as the floating point model."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "post-training-quant.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

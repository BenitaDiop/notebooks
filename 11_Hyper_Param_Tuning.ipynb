{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-Parameter Tuning with Keras, PipelineAI, and MLflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.callbacks import Callback\n",
    "from keras.layers import Dense, Flatten\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "import click\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import plot_model\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLflowLogger(Callback):\n",
    "    \"\"\"\n",
    "    Keras callback for logging metrics and final model with MLflow.\n",
    "\n",
    "    Metrics are logged after every epoch. The logger keeps track of the best model based on the\n",
    "    validation metric. At the end of the training, the best model is logged with MLflow.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, x_train, y_train, x_test, y_test,\n",
    "                 **kwargs):\n",
    "        self._model = model\n",
    "        self._best_val_loss = math.inf\n",
    "        self._train = (x_train, y_train)\n",
    "        self._valid = (x_test, y_test)\n",
    "        self._pyfunc_params = kwargs\n",
    "        self._best_weights = None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"\n",
    "        Log Keras metrics with MLflow. Update the best model if the model improved on the validation\n",
    "        data.\n",
    "        \"\"\"\n",
    "        if not logs:\n",
    "            return\n",
    "        for name, value in logs.items():\n",
    "            if name.startswith(\"val_\"):\n",
    "                name = \"valid_\" + name[4:]\n",
    "            else:\n",
    "                name = \"train_\" + name\n",
    "            mlflow.log_metric(name, value)\n",
    "        val_loss = logs[\"val_loss\"]\n",
    "        if val_loss < self._best_val_loss:\n",
    "            # Save the \"best\" weights\n",
    "            self._best_val_loss = val_loss\n",
    "            self._best_weights = [x.copy() for x in self._model.get_weights()]\n",
    "\n",
    "    def on_train_batch_begin(self, *args, **kwargs):\n",
    "        pass\n",
    "            \n",
    "    def on_train_batch_end(self, *args, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def on_train_end(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Log the best model with MLflow and evaluate it on the train and validation data so that the\n",
    "        metrics stored with MLflow reflect the logged model.\n",
    "        \"\"\"\n",
    "        self._model.set_weights(self._best_weights)\n",
    "        x, y = self._train\n",
    "        train_res = self._model.evaluate(x=x, y=y)\n",
    "        for name, value in zip(self._model.metrics_names, train_res):\n",
    "            mlflow.log_metric(\"train_{}\".format(name), value)\n",
    "        x, y = self._valid\n",
    "        valid_res = self._model.evaluate(x=x, y=y)\n",
    "        for name, value in zip(self._model.metrics_names, valid_res):\n",
    "            mlflow.log_metric(\"valid_{}\".format(name), value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify `user_id`\n",
    "* `<YOUR_USER_ID>`  - 8 character id that uniquely identifies the PipelineAI user.  You will see the UserId in the upper right hand corner of the Settings tab after you login to [PipelineAI Community Edition](https://community.cloud.pipeline.ai)\n",
    "\n",
    "![user-id](https://pipeline.ai/assets/img/user-id.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_id = <YOUR_USER_ID>\n",
    "user_id = ''\n",
    "\n",
    "model_name = 'mnist'\n",
    "model_tag = 'v1'\n",
    "\n",
    "tracking_uri = 'https://community.cloud.pipeline.ai'\n",
    "    \n",
    "def run(epochs_list, batch_size_list):\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "    experiment_name = '%s%s-%s' % (user_id, model_name, model_tag)\n",
    "    \n",
    "    # This will create and set the experiment\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    for epochs in epochs_list:\n",
    "        for batch_size in batch_size_list:\n",
    "            with mlflow.start_run() as run:\n",
    "                print('***')\n",
    "                print('***')\n",
    "                print('*** Experiment:  %s' % (experiment_name))\n",
    "                print('*** Run Id:  %s' % (run.info.run_uuid))\n",
    "                print('*** Training with epochs %s and batch_size %s' % (epochs, batch_size))\n",
    "                print('***')\n",
    "                \n",
    "                mlflow.log_param('epochs', str(epochs))\n",
    "                mlflow.log_param('batch_size', str(batch_size))\n",
    "\n",
    "                mnist = tf.keras.datasets.mnist\n",
    "\n",
    "                (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "                x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "                model = tf.keras.models.Sequential([\n",
    "                  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "                  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "                  tf.keras.layers.Dropout(0.2),\n",
    "                  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "                ])\n",
    "\n",
    "                model.compile(optimizer='adam',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "                history = model.fit(\n",
    "                    x=x_train,\n",
    "                    y=y_train,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[MLflowLogger(model=model,\n",
    "                                            x_train=x_train,\n",
    "                                            y_train=y_train,\n",
    "                                            x_test=x_test,\n",
    "                                            y_test=y_test,\n",
    "                                            domain={},\n",
    "                                            artifact_path=\"model\",\n",
    "                                            image_dims=(28, 28))\n",
    "                              ])\n",
    "\n",
    "                model.evaluate(x_test, y_test)\n",
    "\n",
    "                saved_model_path = tf.contrib.saved_model.save_keras_model(model, \"./mnist_model/pipeline_tfserving\")\n",
    "                if type(saved_model_path) != str:\n",
    "                    saved_model_path = saved_model_path.decode('utf-8')\n",
    "\n",
    "                # From the following:  https://keras.io/visualization/\n",
    "                print(history)\n",
    "                print(history.history)\n",
    " \n",
    "                # Plot training & validation accuracy values\n",
    "                plt.plot(history.history['acc'])\n",
    "                plt.plot(history.history['val_acc'])\n",
    "                plt.title('Model Accuracy')\n",
    "                plt.ylabel('Accuracy')\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.legend(['Train', 'Test'], loc='upper left')\n",
    "                plt.show()\n",
    "                plt.savefig('mnist_model/viz_training_accuracy.png')\n",
    "\n",
    "                # Plot training & validation loss values\n",
    "                plt.plot(history.history['loss'])\n",
    "                plt.plot(history.history['val_loss'])\n",
    "                plt.title('Model Loss')\n",
    "                plt.ylabel('Loss')\n",
    "                plt.xlabel('Epoch')\n",
    "                plt.legend(['Train', 'Test'], loc='upper left')\n",
    "                plt.show()\n",
    "                plt.savefig('./mnist_model/viz_training_loss.png')\n",
    "\n",
    "                plot_model(model, to_file='./mnist_model/viz_pipeline_model.png')\n",
    "\n",
    "                mlflow.log_artifacts(saved_model_path)\n",
    "                mlflow.log_artifact('./mnist_model/pipeline_conda_environment.yaml')\n",
    "                mlflow.log_artifact('./mnist_model/pipeline_train.py') \n",
    "                mlflow.log_artifact('./mnist_model/pipeline_invoke_python.py')\n",
    "                mlflow.log_artifact('./mnist_model/pipeline_modelserver.properties')\n",
    "                mlflow.log_artifact('./mnist_model/pipeline_tfserving.properties')\n",
    "                mlflow.log_artifact('./mnist_model/MLproject')\n",
    "                mlflow.log_artifact('./mnist_model/pipeline_condarc')\n",
    "                mlflow.log_artifact('./mnist_model/pipeline_ignore')\n",
    "                mlflow.log_artifact('./mnist_model/pipeline_setup.sh')\n",
    "                mlflow.log_artifact('./mnist_model/viz_pipeline_model.png')\n",
    "                mlflow.log_artifact('./mnist_model/viz_training_accuracy.png')\n",
    "                mlflow.log_artifact('./mnist_model/viz_training_loss.png')            \n",
    "\n",
    "                mlflow.end_run()\n",
    "\n",
    "    print('***')\n",
    "    print('***')\n",
    "    print('*** Completed Experiment: %s' % (experiment_name))\n",
    "    print('***')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call `run()` with any combination of `epochs_list` and `batch_size_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(epochs_list=[2, 5], batch_size_list=[64, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
